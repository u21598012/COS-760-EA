{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjxl0BUuecNWlniBmqO2AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u21598012/COS-760-EA/blob/BERT-fine-tuned/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "BJtaHDsDS6FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faiNoncvWAXe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a6740c76-0edb-44b4-b1f3-7ecb1f0b321f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'optuna'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1a17d9a5c1c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m from transformers import (\n\u001b[1;32m      8\u001b[0m     \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import optuna\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForMaskedLM,\n",
        "    AutoModel,\n",
        "    AutoConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback,\n",
        "    AutoModelForSequenceClassification, get_scheduler\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('processed_data_it3.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df['stemmed_tokens']\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "labels = df[emotion_labels].values.tolist()\n",
        "df[emotion_labels] = df[emotion_labels].astype(int)\n"
      ],
      "metadata": {
        "id": "KthscF0ALDCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-finetuned-hausa\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "lhhV_SPeLErQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'].tolist(), df[emotion_labels].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/bert-base-multilingual-cased-finetuned-hausa\")\n"
      ],
      "metadata": {
        "id": "WeDd1NGDLG8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n"
      ],
      "metadata": {
        "id": "P0toCqzVLKb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)"
      ],
      "metadata": {
        "id": "6XeH8BLTLMQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init(trial):\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"Davlan/bert-base-multilingual-cased-finetuned-hausa\",\n",
        "        num_labels=len(emotion_labels),\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"Davlan/bert-base-multilingual-cased-finetuned-hausa\",\n",
        "#     num_labels=len(emotion_labels),\n",
        "#     problem_type=\"multi_label_classification\"\n",
        "# )"
      ],
      "metadata": {
        "id": "bSx_LznhLNjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     num_train_epochs=2,\n",
        "#     per_device_train_batch_size=24,\n",
        "#     per_device_eval_batch_size=24,\n",
        "#     save_strategy=\"no\",\n",
        "#     logging_dir='./logs',\n",
        "#     logging_steps=10,\n",
        "#     load_best_model_at_end=True,\n",
        "#     optim=\"adamw_torch\"\n",
        "# )\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./optuna_results\", # Use a different output directory for tuning\n",
        "#     per_device_train_batch_size=4, # You might tune this\n",
        "#     per_device_eval_batch_size=16,  # You might tune this\n",
        "#     save_strategy=\"no\",\n",
        "#     logging_dir='./optuna_logs',    # Use a different logging directory\n",
        "#     logging_steps=10,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=\"f1\", # Specify the metric to optimize\n",
        "#     greater_is_better=True, # Specify if a higher metric is better\n",
        "#     learning_rate=1.6788168340923137e-05,\n",
        "#     num_train_epochs=4,\n",
        "#     seed=3\n",
        "# )\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./optuna_results\", # Use a different output directory for tuning\n",
        "    per_device_train_batch_size=16, # You might tune this\n",
        "    per_device_eval_batch_size=16,  # You might tune this\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir='./optuna_logs',    # Use a different logging directory\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\", # Specify the metric to optimize\n",
        "    greater_is_better=True # Specify if a higher metric is better\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "72ojOTSmLPxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    preds = (torch.sigmoid(torch.tensor(logits)) > 0.5).int()\n",
        "    labels = torch.tensor(labels).int()\n",
        "    report = classification_report(labels, preds, output_dict=True, zero_division=0)\n",
        "    return {\n",
        "        'f1_macro': f1_score(labels, preds, average='macro'),\n",
        "        'f1_micro': f1_score(labels, preds, average='micro'),\n",
        "        'f1_samples': f1_score(labels, preds, average='samples'),\n",
        "        'accuracy': (preds == labels).float().mean().item(),\n",
        "    }\n",
        "\n",
        "def custom_loss(outputs, labels):\n",
        "    return BCEWithLogitsLoss()(outputs.logits, labels)"
      ],
      "metadata": {
        "id": "h-YKQg3YLRXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    model_init=model_init )\n",
        "\n",
        "best_trial = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    n_trials=20\n",
        ")\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(best_trial)\n",
        "\n",
        "# trainer.train()\n",
        "\n",
        "# metrics = trainer.evaluate()\n",
        "# print(\"Evaluation metrics:\", metrics)"
      ],
      "metadata": {
        "id": "P1wCKt5xLS2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of records : \", len(df))\n",
        "\n",
        "count_anger = df['anger'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'anger':\", count_anger)\n",
        "\n",
        "count_disgust = df['disgust'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'disgust':\", count_disgust)\n",
        "\n",
        "count_fear = df['fear'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'fear':\", count_fear)\n",
        "\n",
        "count_joy = df['joy'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'joy':\", count_joy)\n",
        "\n",
        "count_sadness = df['sadness'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'sadness':\", count_sadness)\n",
        "\n",
        "count_surprise = df['surprise'].value_counts().get(1, 0)\n",
        "print(\"Occurrences of 'surprise':\", count_surprise)\n"
      ],
      "metadata": {
        "id": "X1lLbCsvLWme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}